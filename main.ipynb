{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangGraph Multi-Agent System\n",
    "\n",
    "This notebook implements the LangGraph Multi-Agent System using Groq's LLM API. All the necessary code is included directly in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "!pip install langchain>=0.1.0 langchain-community>=0.0.10 langgraph>=0.0.10 pydantic>=2.0.0 python-dotenv>=1.0.0 tavily-python>=0.1.9 requests>=2.31.0 groq>=0.4.0 langchain-core>=0.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set Up Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from google.colab import userdata\n",
    "import os\n",
    "\n",
    "# Set up environment variables\n",
    "os.environ['GROQ_API_KEY'] = userdata.get('GROQ_API_KEY')\n",
    "os.environ['TAVILY_API_KEY'] = userdata.get('TAVILY_API_KEY')\n",
    "os.environ['EMAIL_ADDRESS'] = userdata.get('EMAIL_ADDRESS')\n",
    "os.environ['EMAIL_CODE'] = userdata.get('EMAIL_CODE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define the Plan Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from typing import List, Dict, Any\n",
    "from pydantic import BaseModel\n",
    "from langchain_core.messages import HumanMessage\n",
    "from groq import Groq\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "class SubTask(BaseModel):\n",
    "    task_id: str\n",
    "    description: str\n",
    "    status: str = \"pending\"\n",
    "    result: str = \"\"\n",
    "    feedback: str = \"\"\n",
    "\n",
    "class PlanAgent:\n",
    "    def __init__(self, client: Groq):\n",
    "        self.client = client\n",
    "        self.system_prompt = \"\"\"You are a planning agent responsible for breaking down complex tasks into smaller, manageable sub-tasks.\n",
    "        For each user request, you should:\n",
    "        1. Analyze the request and identify the main components\n",
    "        2. Break it down into logical sub-tasks\n",
    "        3. Ensure sub-tasks are clear, specific, and actionable\n",
    "        4. Consider dependencies between tasks\n",
    "        5. Return a list of sub-tasks in order of execution\"\"\"\n",
    "\n",
    "    def plan(self, state: Dict[str, Any]) -> List[SubTask]:\n",
    "        \"\"\"Generate a plan by breaking down the user's request into sub-tasks.\"\"\"\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": self.system_prompt},\n",
    "            {\"role\": \"user\", \"content\": state[\"messages\"][-1].content}\n",
    "        ]\n",
    "        \n",
    "        response = self.client.chat.completions.create(\n",
    "            messages=messages,\n",
    "            model=\"llama-3.3-70b-versatile\",\n",
    "            temperature=0.7\n",
    "        )\n",
    "        \n",
    "        result = response.choices[0].message.content\n",
    "        \n",
    "        # Parse the LLM response into SubTask objects\n",
    "        tasks = []\n",
    "        for i, task_desc in enumerate(result.split('\\n')):\n",
    "            if task_desc.strip():\n",
    "                tasks.append(SubTask(\n",
    "                    task_id=f\"task_{i+1}\",\n",
    "                    description=task_desc.strip(),\n",
    "                    status=\"pending\"\n",
    "                ))\n",
    "        return tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define the Tool Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from typing import Dict, Any, List\n",
    "from pydantic import BaseModel\n",
    "from langchain_core.messages import HumanMessage\n",
    "from groq import Groq\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from tavily import TavilyClient\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "\n",
    "class ToolAgent:\n",
    "    def __init__(self, client: Groq):\n",
    "        self.client = client\n",
    "        self.tools = {\n",
    "            'search': TavilySearchResults(max_results=5),\n",
    "            'extract': TavilyClient(api_key=os.getenv('TAVILY_API_KEY')).extract,\n",
    "            'email': self._send_email,\n",
    "            'generate_image': self._generate_image,\n",
    "            'generate_audio': self._generate_audio\n",
    "        }\n",
    "        \n",
    "        self.system_prompt = \"\"\"You are a tool agent responsible for executing specific tasks using available tools.\n",
    "        For each task, you should:\n",
    "        1. Identify the appropriate tool for the task\n",
    "        2. Execute the task using the selected tool\n",
    "        3. Return the result and any relevant feedback\n",
    "        4. Handle errors gracefully and provide meaningful feedback\"\"\"\n",
    "\n",
    "    def execute_task(self, state: Dict[str, Any], task: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Execute a specific task using the appropriate tool.\"\"\"\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": self.system_prompt},\n",
    "            {\"role\": \"user\", \"content\": task[\"description\"]}\n",
    "        ]\n",
    "        \n",
    "        response = self.client.chat.completions.create(\n",
    "            messages=messages,\n",
    "            model=\"llama-3.3-70b-versatile\",\n",
    "            temperature=0.7\n",
    "        )\n",
    "        \n",
    "        result = response.choices[0].message.content\n",
    "        \n",
    "        # Execute the appropriate tool based on the task\n",
    "        tool_name = self._identify_tool(result)\n",
    "        if tool_name in self.tools:\n",
    "            tool_result = self.tools[tool_name](task[\"description\"])\n",
    "            feedback = self._generate_feedback(tool_result)\n",
    "            return {\n",
    "                \"result\": tool_result,\n",
    "                \"status\": \"completed\",\n",
    "                \"feedback\": feedback\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                \"result\": \"No appropriate tool found for this task\",\n",
    "                \"status\": \"failed\",\n",
    "                \"feedback\": \"Please try rephrasing the task\"\n",
    "            }\n",
    "\n",
    "    def _send_email(self, subject: str, body: str, to_email: str) -> None:\n",
    "        \"\"\"Send an email using SMTP.\"\"\"\n",
    "        smtp_server = 'smtp.gmail.com'\n",
    "        smtp_port = 587\n",
    "        sender_email = os.getenv('EMAIL_ADDRESS')\n",
    "        password = os.getenv('EMAIL_CODE')\n",
    "\n",
    "        message = MIMEText(body, 'plain')\n",
    "        message['From'] = sender_email\n",
    "        message['To'] = to_email\n",
    "        message['Subject'] = subject\n",
    "\n",
    "        try:\n",
    "            server = smtplib.SMTP(smtp_server, smtp_port)\n",
    "            server.starttls()\n",
    "            server.login(sender_email, password)\n",
    "            server.sendmail(sender_email, to_email, message.as_string())\n",
    "            server.quit()\n",
    "            print(\"Email sent successfully!\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to send email: {e}\")\n",
    "\n",
    "    def _generate_image(self, prompt: str) -> str:\n",
    "        \"\"\"Generate an image using Groq.\"\"\"\n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                messages=[{\"role\": \"user\", \"content\": f\"Generate an image based on this description: {prompt}\"}],\n",
    "                model=\"llama-3.3-70b-versatile\",\n",
    "                temperature=0.7\n",
    "            )\n",
    "            return f\"Image generated successfully: {response.choices[0].message.content}\"\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating image: {e}\")\n",
    "            return None\n",
    "\n",
    "    def _generate_audio(self, text: str, voice: str = \"alloy\") -> str:\n",
    "        \"\"\"Generate audio using Groq.\"\"\"\n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                messages=[{\"role\": \"user\", \"content\": f\"Generate audio for this text: {text}\"}],\n",
    "                model=\"llama-3.3-70b-versatile\",\n",
    "                temperature=0.7\n",
    "            )\n",
    "            return f\"Audio generated successfully: {response.choices[0].message.content}\"\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating audio: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Define the Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from typing import Dict, Any, List, TypedDict, Annotated\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "import operator\n",
    "from groq import Groq\n",
    "from langchain_core.messages import HumanMessage\n",
    "import os\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[List[BaseMessage], operator.add]\n",
    "    tasks: List[SubTask]\n",
    "    current_task_index: int\n",
    "    feedback: str\n",
    "\n",
    "def create_workflow():\n",
    "    # Initialize agents with Groq\n",
    "    client = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))\n",
    "    plan_agent = PlanAgent(client)\n",
    "    tool_agent = ToolAgent(client)\n",
    "    \n",
    "    # Create workflow graph\n",
    "    workflow = StateGraph(AgentState)\n",
    "    \n",
    "    # Define nodes\n",
    "    def plan_node(state: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Generate initial plan or update plan based on feedback.\"\"\"\n",
    "        if not state.get(\"tasks\"):\n",
    "            # Initial planning\n",
    "            tasks = plan_agent.plan(state)\n",
    "        else:\n",
    "            # Update plan based on feedback\n",
    "            tasks = plan_agent.update_plan(state, state.get(\"feedback\", \"\"))\n",
    "        \n",
    "        return {\n",
    "            \"messages\": state[\"messages\"],\n",
    "            \"tasks\": tasks,\n",
    "            \"current_task_index\": 0,\n",
    "            \"feedback\": \"\"\n",
    "        }\n",
    "    \n",
    "    def execute_node(state: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Execute the current task.\"\"\"\n",
    "        current_task = state[\"tasks\"][state[\"current_task_index\"]]\n",
    "        result = tool_agent.execute_task(state, current_task.dict())\n",
    "        \n",
    "        # Update task with result and feedback\n",
    "        current_task.result = result[\"result\"]\n",
    "        current_task.status = result[\"status\"]\n",
    "        current_task.feedback = result[\"feedback\"]\n",
    "        \n",
    "        return {\n",
    "            \"messages\": state[\"messages\"] + [HumanMessage(content=result[\"result\"])],\n",
    "            \"tasks\": state[\"tasks\"],\n",
    "            \"current_task_index\": state[\"current_task_index\"],\n",
    "            \"feedback\": result[\"feedback\"]\n",
    "        }\n",
    "    \n",
    "    def should_continue(state: Dict[str, Any]) -> str:\n",
    "        \"\"\"Determine if we should continue with the next task or go back to planning.\"\"\"\n",
    "        if state[\"current_task_index\"] >= len(state[\"tasks\"]) - 1:\n",
    "            return \"plan\" if state[\"feedback\"] else \"end\"\n",
    "        return \"execute\"\n",
    "    \n",
    "    # Add nodes to workflow\n",
    "    workflow.add_node(\"plan\", plan_node)\n",
    "    workflow.add_node(\"execute\", execute_node)\n",
    "    \n",
    "    # Add edges\n",
    "    workflow.add_edge(START, \"plan\")\n",
    "    workflow.add_conditional_edges(\n",
    "        \"execute\",\n",
    "        should_continue,\n",
    "        {\n",
    "            \"plan\": \"plan\",\n",
    "            \"execute\": \"execute\",\n",
    "            \"end\": END\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Compile workflow\n",
    "    return workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def test_environment():\n",
    "    # Test Groq API\n",
    "    try:\n",
    "        client = Groq(api_key=os.getenv('GROQ_API_KEY'))\n",
    "        response = client.chat.completions.create(\n",
    "            messages=[{\"role\": \"user\", \"content\": \"Hello\"}],\n",
    "            model=\"llama-3.3-70b-versatile\"\n",
    "        )\n",
    "        print(\"‚úÖ Groq API key is working\")\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå Groq API key error:\", str(e))\n",
    "    \n",
    "    # Test Tavily\n",
    "    try:\n",
    "        tavily_client = TavilyClient(api_key=os.getenv('TAVILY_API_KEY'))\n",
    "        response = tavily_client.search(\"test query\")\n",
    "        print(\"‚úÖ Tavily API key is working\")\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå Tavily API key error:\", str(e))\n",
    "    \n",
    "    # Test Email\n",
    "    email_code = os.getenv('EMAIL_CODE')\n",
    "    if email_code and len(email_code.replace(\" \", \"\")) == 16:\n",
    "        print(\"‚úÖ Email configuration looks correct\")\n",
    "    else:\n",
    "        print(\"‚ùå Email configuration error: Make sure you have a valid 16-character app password\")\n",
    "\n",
    "test_environment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Run the Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def run_workflow(task_description: str):\n",
    "    workflow = create_workflow()\n",
    "    \n",
    "    print(\"\\nü§ñ Processing your request...\\n\")\n",
    "    \n",
    "    # Run workflow with initial user query\n",
    "    for state in workflow.stream({\n",
    "        \"messages\": [HumanMessage(content=task_description)]\n",
    "    }):\n",
    "        if \"__end__\" not in state:\n",
    "            # Format the output in a more readable way\n",
    "            if \"tasks\" in state[\"plan\"]:\n",
    "                print(\"üìã Plan Generated:\\n\")\n",
    "                for task in state[\"plan\"][\"tasks\"]:\n",
    "                    if task.description.startswith(\"**\"):\n",
    "                        print(f\"\\n{task.description.strip('*')}\")\n",
    "                    else:\n",
    "                        print(f\"- {task.description}\")\n",
    "                    if task.result:\n",
    "                        print(f\"  Result: {task.result}\")\n",
    "                    if task.feedback:\n",
    "                        print(f\"  Feedback: {task.feedback}\")\n",
    "                print(\"\\n---\")\n",
    "\n",
    "# Example usage\n",
    "run_workflow(\"Plan a weekend trip to the mountains. Assign specific responsibilities to each agent.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Try Different Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Example 1: Research AI frameworks\n",
    "run_workflow(\"Research and summarize the top 5 AI frameworks for building chatbots. Each agent should handle one part of the process.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Example 2: Climate change report\n",
    "run_workflow(\"You are a team of AI agents working on a report about climate change. One agent should research, one should write, and one should proofread. Coordinate and deliver the final report.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Example 3: To-do list app\n",
    "run_workflow(\"Build a basic to-do list web app using React. Assign the coding, documentation, and testing tasks to the appropriate agents.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
